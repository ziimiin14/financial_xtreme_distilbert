{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnbc_scrape_pipeline.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"19aDBYXiZFfeCCjOwd2ilULOI39_iE2W3","authorship_tag":"ABX9TyPPkEzK0+KAP+2dSeP7KHXg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3k2E2hKD6H2g","executionInfo":{"status":"ok","timestamp":1656312432110,"user_tz":-480,"elapsed":41021,"user":{"displayName":"James Leon","userId":"03089015147305343322"}},"outputId":"be4c681f-53cf-4994-d673-2addee7ef14a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting selenium\n","  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n","\u001b[K     |████████████████████████████████| 981 kB 5.4 MB/s \n","\u001b[?25hCollecting trio~=0.17\n","  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n","\u001b[K     |████████████████████████████████| 358 kB 46.4 MB/s \n","\u001b[?25hCollecting urllib3[secure,socks]~=1.26\n","  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 56.3 MB/s \n","\u001b[?25hCollecting trio-websocket~=0.9\n","  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n","Collecting sniffio\n","  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Collecting async-generator>=1.9\n","  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n","Collecting outcome\n","  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n","Collecting wsproto>=0.14\n","  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2022.6.15)\n","Collecting cryptography>=1.3.4\n","  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 28.5 MB/s \n","\u001b[?25hCollecting pyOpenSSL>=0.14\n","  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n","Collecting h11<1,>=0.9.0\n","  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 5.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n","Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed async-generator-1.10 cryptography-37.0.2 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.3.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 urllib3-1.26.9 wsproto-1.1.0\n","Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:10 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,521 kB]\n","Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,866 kB]\n","Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,013 kB]\n","Get:17 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [22.8 kB]\n","Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,026 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,297 kB]\n","Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,037 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,047 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,298 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n","Get:24 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n","Fetched 15.4 MB in 3s (4,430 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n","Suggested packages:\n","  webaccounts-chromium-extension unity-chromium-extension\n","The following NEW packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-chromedriver\n","  chromium-codecs-ffmpeg-extra\n","0 upgraded, 4 newly installed, 0 to remove and 53 not upgraded.\n","Need to get 89.8 MB of archives.\n","After this operation, 302 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 101.0.4951.64-0ubuntu0.18.04.1 [1,142 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 101.0.4951.64-0ubuntu0.18.04.1 [78.5 MB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 101.0.4951.64-0ubuntu0.18.04.1 [4,980 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 101.0.4951.64-0ubuntu0.18.04.1 [5,153 kB]\n","Fetched 89.8 MB in 5s (18.9 MB/s)\n","Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n","(Reading database ... 155639 files and directories currently installed.)\n","Preparing to unpack .../chromium-codecs-ffmpeg-extra_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-codecs-ffmpeg-extra (101.0.4951.64-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser.\n","Preparing to unpack .../chromium-browser_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-browser (101.0.4951.64-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser-l10n.\n","Preparing to unpack .../chromium-browser-l10n_101.0.4951.64-0ubuntu0.18.04.1_all.deb ...\n","Unpacking chromium-browser-l10n (101.0.4951.64-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-chromedriver.\n","Preparing to unpack .../chromium-chromedriver_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-chromedriver (101.0.4951.64-0ubuntu0.18.04.1) ...\n","Setting up chromium-codecs-ffmpeg-extra (101.0.4951.64-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser (101.0.4951.64-0ubuntu0.18.04.1) ...\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n","Setting up chromium-chromedriver (101.0.4951.64-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser-l10n (101.0.4951.64-0ubuntu0.18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n"]}],"source":["!pip install selenium\n","!apt-get update # to update ubuntu to correctly run apt install\n","!apt install chromium-chromedriver"]},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","from selenium import webdriver\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC\n","import re\n","from collections import deque\n","import pandas as pd\n"],"metadata":{"id":"jWHZANWX6Qt3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process(sentence,fil):\n","  return fil.sub(' ',sentence)\n","\n","def run():\n","    # Declare variable for chromedriver\n","    options = webdriver.ChromeOptions()\n","    options.add_argument('--headless')\n","    options.add_argument('--no-sandbox')\n","    options.add_argument('--disable-dev-shm-usage')\n","    driver = webdriver.Chrome('chromedriver',options=options)\n","\n","    # Declare variable for selenium scraping\n","    stock_codes={'AAPL':'(Apple|AAPL)','MSFT':'(Microsoft|MSFT)','AMZN':'(Amazon|AMZN)','META':'(Meta|META)','GOOGL':'(Alphabet|Google|GOOGL)','BRK.B':'(Berkshire|BRK.B)','TSLA':'(Tesla|TSLA)','NVDA':'(Nvidia|NVDA)','JPM':'(JPMorgan|JPM)'}\n","    title = []\n","    href = []\n","    tc = []\n","    mention = []\n","\n","    # Ask for user input for specific stock news from stock_code list\n","    print(200*'-')\n","    sc = input(f'Choose a stock: \\n{list(stock_codes.keys())} \\n-->')\n","\n","    # Scrape specific news title and href\n","    print(200*'-')\n","    print(f'-->Scraping News for {sc} stock<--\\n')\n","    url = f'https://www.cnbc.com/quotes/{sc}?tab=news'\n","    driver.get(url)\n","    try:\n","      element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"LatestNews-newsTabButton\")))\n","      element.click()\n","\n","      element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"LatestNews-newsTabButton\")))\n","      element.click()\n","    except:\n","      print(f\"Cannot find 2nd View More button for {sc}\")\n","\n","    d = driver.page_source\n","    soup = BeautifulSoup(d,'html.parser')\n","    group = soup.find_all('div',attrs={'data-analytics':'QuotePage-QuoteNews-1'})\n","    headlines = deque(group[0].find_all('a'))\n","\n","    final_headlines = []\n","\n","    # Check whether it's a legit headline for that news. Video/Club/Pro news are all being removed.\n","    while headlines:\n","      temp = headlines.popleft()\n","\n","      if temp['class'][0] != 'LatestNews-headline':\n","        headlines.popleft()\n","      else:\n","        if not temp.img:\n","          final_headlines.append(temp)\n","\n","    for x in final_headlines:\n","      tc.append(sc)\n","      mention.append(stock_codes[sc])\n","      title.append(x['title'])\n","      href.append(x['href'])\n","    \n","    # Declare a dataframe\n","    df = pd.DataFrame({'Symbol':tc,'Mention':mention,'title':title,'link':href})\n","\n","    text_list = []\n","\n","    # Open each href link and read the keypoints text or body texts\n","    for m,url_new in zip(df['Mention'],df['link']):\n","      driver.get(url_new)\n","      filter = re.compile(f'{m}')\n","      soup_news = BeautifulSoup(driver.page_source,'html.parser')\n","      keyPoint = soup_news.find_all('div',attrs={'data-test':'keyPoints-1'})\n","\n","      # If there is no keypoints to be concatenated into sentence\n","      if not keyPoint:\n","        body = soup_news.find_all('div',attrs={'data-module':'ArticleBody'})\n","        group = body[0].find_all('div',attrs={'class':'group'})\n","        paragraphs = []\n","        for g in group:\n","          p_temp = g.find_all('p')\n","          for p in p_temp: \n","            paragraphs.append(p)\n","\n","        text = ''\n","        count = 0\n","        \n","        # For each paragraph, apply regex filter to find the specific companies mentioned and concatenate the paragraph and next paragraph into sentence\n","        for p in paragraphs:\n","          if filter.search(p.text):\n","            text += p.text.strip()\n","            count += 1\n","          if count == 2:\n","            break\n","\n","        # If there is no specific companies mentioned in paragraphs. Just choose 1st and 2nd paragraphs and concatenate into sentence\n","        if not text:\n","          if len(paragraphs) > 1:\n","            text = paragraphs[0].text.strip() + paragraphs[1].text.strip()\n","          else:\n","            text = paragraphs[0].text.strip()\n","\n","        text_list.append(text)\n","    \n","      # Concatenate all keyspoint into sentence\n","      else:\n","        li = keyPoint[0].find_all('li')\n","        text = ''\n","        for t in li:\n","          text += t.text.strip()\n","        text_list.append(text)\n","\n","    df['sentence'] = text_list\n","\n","    # Apply regex for sentence to remove \\xa0 symbol\n","    f = re.compile(f'\\xa0')\n","    df['sentence'] = df['sentence'].apply(process,args=(f,))\n","    driver.quit()\n","    print('-->Done<--\\n')\n","\n","    print(df)"],"metadata":{"id":"-gjbJqa_6l4N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run to scrape news for specific stocks.\n","run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kDEAWkCS6sVq","executionInfo":{"status":"ok","timestamp":1656312549218,"user_tz":-480,"elapsed":25811,"user":{"displayName":"James Leon","userId":"03089015147305343322"}},"outputId":"f2f11159-bd32-4364-fe1c-6d4134a12b63"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","Choose a stock: \n","['AAPL', 'MSFT', 'AMZN', 'META', 'GOOGL', 'BRK.B', 'TSLA', 'NVDA', 'JPM'] \n","-->AAPL\n","--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","-->Scraping News for AAPL stock<--\n","\n","-->Done<--\n","\n","  Symbol       Mention                                              title  \\\n","0   AAPL  (Apple|AAPL)         Tech leaders react to Roe v. Wade reversal   \n","1   AAPL  (Apple|AAPL)  Roe v. Wade's demise forces companies to grapp...   \n","2   AAPL  (Apple|AAPL)  Disney, Apple and Amazon keep waiting as NFL c...   \n","3   AAPL  (Apple|AAPL)  Apple responds to Roe v. Wade rollback, covers...   \n","4   AAPL  (Apple|AAPL)  Amazon to invest $23 million to increase Seatt...   \n","5   AAPL  (Apple|AAPL)  Tim Cook gives clearest hint yet that Apple's ...   \n","6   AAPL  (Apple|AAPL)  Mark Mobius shares investor tips on India's 'i...   \n","7   AAPL  (Apple|AAPL)  Apple CEO Tim Cook recommends this decision-ma...   \n","\n","                                                link  \\\n","0  https://www.cnbc.com/2022/06/24/tech-execs-rea...   \n","1  https://www.cnbc.com/2022/06/24/roe-v-wade-abo...   \n","2  https://www.cnbc.com/2022/06/24/disney-apple-a...   \n","3  https://www.cnbc.com/2022/06/24/apple-responds...   \n","4  https://www.cnbc.com/2022/06/23/amazon-to-inve...   \n","5  https://www.cnbc.com/2022/06/22/tim-cook-gives...   \n","6  https://www.cnbc.com/2022/06/22/mark-mobius-on...   \n","7  https://www.cnbc.com/2022/06/21/tim-cook-this-...   \n","\n","                                            sentence  \n","0  Noteworthy tech executives spoke out publicly ...  \n","1  The Supreme Court decision will have far-reach...  \n","2  There’s no set timeline for a Sunday Ticket de...  \n","3  Apple employees can use their company benefits...  \n","4  Amazon said Thursday that it’s giving minority...  \n","5  Apple CEO Tim Cook recently gave the closest t...  \n","6  India is now “emerging as something very excit...  \n","7  Apple CEO Tim Cook says there’s at least one q...  \n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"xU0VHAEv6zQM"},"execution_count":null,"outputs":[]}]}